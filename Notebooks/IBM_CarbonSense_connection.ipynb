{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "You-0GRMI-3w"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install ibm-watson-machine-learning ibm_watson ibm-cloud-sdk-core\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from ibm_watson import DiscoveryV2\n",
        "from ibm_watson_machine_learning import APIClient\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
      ],
      "metadata": {
        "id": "4orEaegz13vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set up environment variables for security\n",
        "# Replace with your actual credentials when you have access\n",
        "API_KEY = \"your_api_key_here\"\n",
        "DISCOVERY_URL = \"your_discovery_url\"\n",
        "DISCOVERY_PROJECT_ID = \"your_discovery_project_id\"\n",
        "\n",
        "# Set up Watson Discovery for document retrieval\n",
        "discovery_authenticator = IAMAuthenticator(API_KEY)\n",
        "discovery = DiscoveryV2(\n",
        "    version='2023-06-15',\n",
        "    authenticator=discovery_authenticator\n",
        ")\n",
        "discovery.set_service_url(DISCOVERY_URL)\n",
        "\n",
        "# Set up Watson Machine Learning for access to foundation models\n",
        "wml_credentials = {\n",
        "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
        "    \"apikey\": API_KEY # Ask Seana for this as she had admin access\n",
        "}\n",
        "\n",
        "wml_client = APIClient(wml_credentials)\n",
        "project_id = \"b10e6698-f168-48c2-afb3-ec6bb6f93d80\"\n",
        "wml_client.set.default_project(project_id)\n",
        "\n",
        "# Carbon footprint specific model - using a foundation model well-suited for scientific analysis\n",
        "model_id = \"ibm/granite-13b-instruct-v2\"  # Or another appropriate IBM model\n"
      ],
      "metadata": {
        "id": "_gDi4er5JEve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def carbon_footprint_rag(query, top_k=5):\n",
        "    \"\"\"\n",
        "    Carbon Footprint Analysis RAG pipeline using IBM Watson services\n",
        "\n",
        "    Args:\n",
        "        query (str): User query about carbon footprint\n",
        "        top_k (int): Number of documents to retrieve\n",
        "\n",
        "    Returns:\n",
        "        dict: Response with retrieved information and analysis\n",
        "    \"\"\"\n",
        "    # Step 1: Retrieve relevant carbon footprint documents from Watson Discovery\n",
        "    # Adding specific carbon footprint related filters\n",
        "    discovery_response = discovery.query(\n",
        "        project_id=DISCOVERY_PROJECT_ID,\n",
        "        natural_language_query=query,\n",
        "        count=top_k,\n",
        "        filter=\"document_type:carbon_report,emission_data,sustainability\",\n",
        "        passages={\n",
        "            \"enabled\": True,\n",
        "            \"count\": 5,\n",
        "            \"fields\": [\"text\", \"emission_metrics\", \"carbon_data\"],\n",
        "            \"characters\": 500,\n",
        "            \"per_document\": True\n",
        "        }\n",
        "    ).get_result()\n",
        "\n",
        "    # Extract relevant passages from the retrieved documents\n",
        "    retrieved_passages = []\n",
        "    carbon_metrics = []\n",
        "\n",
        "    for result in discovery_response.get('results', []):\n",
        "        # Extract main content\n",
        "        if 'text' in result:\n",
        "            retrieved_passages.append(result['text'])\n",
        "\n",
        "        # Extract specific carbon metrics when available\n",
        "        if 'emission_metrics' in result:\n",
        "            carbon_metrics.append(result['emission_metrics'])\n",
        "\n",
        "        # Check for passages which might contain more specific information\n",
        "        for passage in result.get('passages', []):\n",
        "            if 'passage_text' in passage:\n",
        "                retrieved_passages.append(passage['passage_text'])\n",
        "\n",
        "    # Create context with focus on carbon data\n",
        "    context = \"\\n\\n\".join(retrieved_passages)\n",
        "\n",
        "    # Add any structured carbon metrics data\n",
        "    if carbon_metrics:\n",
        "        metrics_summary = \"\\nCARBON METRICS SUMMARY:\\n\" + json.dumps(carbon_metrics, indent=2)\n",
        "        context += metrics_summary\n",
        "\n",
        "    # Step 2: Generate carbon analysis using Watson Machine Learning foundation model\n",
        "    carbon_analysis_prompt = f\"\"\"\n",
        "    You are a carbon footprint analysis expert. Use the following retrieved information to provide\n",
        "    detailed analysis about the carbon footprint question.\n",
        "\n",
        "    CONTEXT INFORMATION:\n",
        "    {context}\n",
        "\n",
        "    USER QUESTION: {query}\n",
        "\n",
        "    Provide a comprehensive analysis that includes:\n",
        "    1. Direct answer to the question with specific carbon metrics when available\n",
        "    2. Recommendations for carbon footprint reduction if applicable\n",
        "    3. Sources of the information from the context\n",
        "    4. Any limitations in the analysis based on the available data\n",
        "\n",
        "    ANALYSIS:\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate the analysis using the WML foundation model\n",
        "    parameters = {\n",
        "        \"decoding_method\": \"greedy\",\n",
        "        \"max_new_tokens\": 500,\n",
        "        \"min_new_tokens\": 100,\n",
        "        \"temperature\": 0.5,  # Lower temperature for more factual responses\n",
        "        \"repetition_penalty\": 1.2,  # Discourage repetition\n",
        "    }\n",
        "\n",
        "    response = wml_client.foundation_models.generate(\n",
        "        model_id=model_id,\n",
        "        text=carbon_analysis_prompt,\n",
        "        parameters=parameters\n",
        "    )\n",
        "\n",
        "    generated_analysis = response[\"results\"][0][\"generated_text\"]\n",
        "\n",
        "    return {\n",
        "        'query': query,\n",
        "        'context_sources': len(retrieved_passages),\n",
        "        'carbon_metrics_found': len(carbon_metrics) > 0,\n",
        "        'analysis': generated_analysis\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "D2gk2zeW1eks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <aim function to execute\n",
        "if __name__ == \"__main__\":\n",
        "    sample_queries = [\n",
        "        \"What is the carbon footprint of cloud computing?\",\n",
        "        \"How can our company reduce emissions from data centers?\",\n",
        "        \"Compare the environmental impact of on-premise vs cloud infrastructure\",\n",
        "        \"What metrics should we track for our corporate carbon footprint report?\"\n",
        "    ]\n",
        "\n",
        "    for query in sample_queries:\n",
        "        print(f\"\\n\\nAnalyzing: {query}\")\n",
        "        try:\n",
        "            result = carbon_footprint_rag(query)\n",
        "            print(f\"Analysis: {result['analysis']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing query: {str(e)}\")"
      ],
      "metadata": {
        "id": "MMpPLQoe1u1P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}