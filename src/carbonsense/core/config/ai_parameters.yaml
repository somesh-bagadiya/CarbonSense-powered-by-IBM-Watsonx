###############################################
# CarbonSense AI Parameters Configuration
###############################################

default:
  # Core model parameters
  model: "watsonx/meta-llama/llama-3-3-70b-instruct"  # Default model for all agents
  temperature: 0.7                         # Controls randomness (0-1)
  top_p: 1.0                              # Nucleus sampling parameter
  # n: 1                                    # Number of completions
  max_tokens: 256                        # Maximum tokens in completion
  # presence_penalty: 0.0                   # Penalty for repeated topics (-2 to 2)
  # frequency_penalty: 0.0                  # Penalty for repeated tokens (-2 to 2)
  # logit_bias: {}                          # Token biasing dictionary
  # stop: []                               # List of stop sequences
  # stream: true                           # Enable streaming responses
  # timeout: 120                           # Request timeout in seconds
  
  # Advanced parameters
  # reasoning_effort: "medium"              # Options: none, low, medium, high
  # seed: null                             # Random seed for reproducibility
  # logprobs: null                         # Return log probabilities
  # top_logprobs: null                     # Number of most likely tokens
  cache_ttl_seconds: 86400

# Agent-specific parameters - only override what differs from defaults
agents:
  query_processor:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.2
    reasoning_effort: "low"
    max_tokens: 256
    sources_tracked: false

  milvus_researcher:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.2        # Lower temperature for more factual/precise responses
    reasoning_effort: "low"  # Higher reasoning for research
    max_tokens: 256        # Larger context for research
    sources_tracked: true   # This agent tracks Milvus

  discovery_researcher:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.2
    reasoning_effort: "low"
    max_tokens: 256
    sources_tracked: true

  serper_researcher:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.2
    reasoning_effort: "low"
    max_tokens: 256
    sources_tracked: true

  answer_consolidator:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.2
    reasoning_effort: "medium"  # Slightly higher for comparative evaluation
    max_tokens: 256
    sources_tracked: true

  answer_formatter:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.2
    reasoning_effort: "low"
    max_tokens: 256
    sources_tracked: false
    
  manager:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.2        # Lower temperature for more precise task management
    reasoning_effort: "low"  # Higher reasoning for management
    max_tokens: 256        # Standard context size
    sources_tracked: false

  unit_normalizer:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.1
    reasoning_effort: "low"
    max_tokens: 256
    sources_tracked: false

  footprint_cache:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.1
    reasoning_effort: "low"
    max_tokens: 256
    sources_tracked: false

  unit_harmoniser:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.1
    reasoning_effort: "low"
    max_tokens: 256
    sources_tracked: false

  metric_ranker:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.1
    reasoning_effort: "low"
    max_tokens: 256
    sources_tracked: false

  usage_logger:
    model: "watsonx/meta-llama/llama-3-3-70b-instruct"
    temperature: 0.1
    reasoning_effort: "low"
    max_tokens: 256
    sources_tracked: false

# Response structure for the final compiler agent output
output_format:
  line1: "Carbon footprint in kg CO2e (numeric value with units)"
  line2: "Creative comparison relating CO2 emissions to real life"
  final_section: "Short, practical suggestions for reducing this carbon footprint"
  source_attribution: true  # Include sources in output

# Data sources tracked
data_sources:
  milvus_database:
    description: "Vector database containing pre-processed carbon footprint data"
    collections:
      - "carbon_embeddings_30m"   # 30M model embeddings
      - "carbon_embeddings_125m"  # 125M model embeddings
      - "carbon_embeddings_granite" # Granite model embeddings (preferred)
  
  watson_discovery:
    description: "External web search for carbon footprint data not in local database"
    confidence_threshold: 0.6   # Minimum confidence score for web results
    max_results: 5             # Maximum number of search results to return